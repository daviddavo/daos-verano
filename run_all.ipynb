{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs everything necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from subprocess import call\n",
    "\n",
    "import requests\n",
    "import papermill as pm\n",
    "\n",
    "def run_notebook(path):\n",
    "    pm.execute_notebook(path, path, progress_bar=True, cwd=os.path.dirname(path))\n",
    "\n",
    "def run_file(path):\n",
    "    call(['python', path])\n",
    "\n",
    "PLATFORMS = [\n",
    "    'aragon',\n",
    "    'daohaus',\n",
    "    'daostack',\n",
    "    # 'governor',\n",
    "    # 'realms',\n",
    "    'snapshot',\n",
    "    # 'tally',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployments\n",
    "\n",
    "Getting the deployments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_from_daoanalyzer(org, dst_path, download_files):\n",
    "    # Zenodo ID\n",
    "    zenodo_id = 10372368\n",
    "    zenodo_dotfile = os.path.join(dst_path, org, '.zenodo-id.txt')\n",
    "\n",
    "    assert download_files, \"download_files cant be empty\"\n",
    "    all_files_available = all( ( os.path.exists(os.path.join(dst_path, org, f)) for f in download_files ) )\n",
    "    old_zenodo_id = -1\n",
    "\n",
    "    if os.path.exists(zenodo_dotfile):\n",
    "        with open(zenodo_dotfile, 'r') as f:\n",
    "            old_zenodo_id = int(f.readline())\n",
    "\n",
    "    if not all_files_available or zenodo_id != old_zenodo_id:\n",
    "        # Download from Zenodo (no API key needed)\n",
    "        url = f\"https://zenodo.org/records/{zenodo_id}/files/archive.zip?download=1\"\n",
    "\n",
    "        archive = f'./DATA/archive-{zenodo_id}.zip'\n",
    "        if not os.path.exists(archive):\n",
    "            r = requests.get(url)\n",
    "            r.raise_for_status()\n",
    "\n",
    "            with open(archive, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "\n",
    "        call(['unzip', '-oj', archive, *[f'{org}/{f}' for f in download_files], '-d', os.path.join(dst_path, org)])\n",
    "        with open(zenodo_dotfile, 'w') as f:\n",
    "            f.write(str(zenodo_id))\n",
    "    else:\n",
    "        print('All files already present')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aragon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files already present\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac3e5e05d854add9ec89019bef5f049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/22 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "get_files_from_daoanalyzer('aragon', 'deployments', ['organizations.csv', 'casts.csv', 'votes.csv'])\n",
    "run_notebook('./deployments/aragon/aragon_get_deployments.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAOhaus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files already present\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa28cddd0a54fb08dcb8c8afed1caa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/25 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "get_files_from_daoanalyzer('daohaus', 'deployments', ['moloches.csv', 'votes.csv', 'proposals.csv'])\n",
    "run_notebook('./deployments/daohaus/daohaus_get_deployments.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAOstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files already present\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a05223049fe4455cb4b28f2ca5efbcf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/19 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "get_files_from_daoanalyzer('daostack', 'deployments', ['daos.csv', 'proposals.csv', 'votes.csv'])\n",
    "run_notebook('./deployments/daostack/daostack_get_deployments.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552416dc706648268ef67e3c97b6d5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/8 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "run_notebook('./deployments/snapshot/snapshot_get_deployments.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8521a7cdf540548fbd8e293ed57c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/17 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "run_notebook('./deployments/combine_and_analyze.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aragon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files already present\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e98661f29bf42de93b71b2577dd681d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/8 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "get_files_from_daoanalyzer('aragon', './proposals/', ['votes.csv'])\n",
    "run_notebook('./proposals/aragon/get_aragon_proposals.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAOhaus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files already present\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db559c5628142fb9db166cfec02cfb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/8 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "get_files_from_daoanalyzer('daohaus', './proposals/', ['proposals.csv'])\n",
    "run_notebook('./proposals/daohaus/get_daohaus_proposals.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAOstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files already present\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9bf8e63630c491e89b9609ec51bf3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/13 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "get_files_from_daoanalyzer('daostack', './proposals/', ['proposals.csv', 'votes.csv'])\n",
    "run_notebook('./proposals/daostack/get_daostack_proposals.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Governor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc337b1d69e47f485846003dc262015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/22 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "# run_notebook('./proposals/governor/get_proposals.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "516c348ec5b0480f9e8fa3100dad812b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1c09d1c0934cf796cf8115ef0992bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/12 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "run_notebook('./proposals/snapshot/download_all_proposals_new.ipynb')\n",
    "run_notebook('./proposals/snapshot/process_snapshot_proposals.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aragon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files already present\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e543bf547e045e1af0437344c98228a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/5 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "get_files_from_daoanalyzer('aragon', './votes/', ['casts.csv'])\n",
    "run_notebook('./votes/aragon/get_aragon_votes.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAOhaus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files already present\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a9b87faec7437a8de2562d0b207c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/8 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "get_files_from_daoanalyzer('daohaus', './votes/', ['votes.csv'])\n",
    "run_notebook('./votes/daohaus/get_daohaus_votes.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAOstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files already present\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cec50fc7155470c8d318247eea2ddf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/4 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    }
   ],
   "source": [
    "get_files_from_daoanalyzer('daostack', './votes/', ['votes.csv'])\n",
    "run_notebook('./votes/daostack/get_daostack_votes.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3154f927ee2f42fbb948d0e62989ce96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/18 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[IPKernelApp] WARNING | debugpy_stream undefined, debugging will not be enabled\n"
     ]
    },
    {
     "ename": "PapermillExecutionError",
     "evalue": "\n---------------------------------------------------------------------------\nException encountered at \"In [2]\":\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[2], line 3\n      1 # read in ../../DATA/deployments/snapshot_deployments.csv\n      2 import pandas as pd\n----> 3 df = pd.read_csv('../../DATA/proposals/snapshot_proposals.csv')\n      4 df.head()\n\nFile /usr/lib/python3.11/site-packages/pandas/util/_decorators.py:211, in deprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper(*args, **kwargs)\n    209     else:\n    210         kwargs[new_arg_name] = new_arg_value\n--> 211 return func(*args, **kwargs)\n\nFile /usr/lib/python3.11/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper(*args, **kwargs)\n    325 if len(args) > num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--> 331 return func(*args, **kwargs)\n\nFile /usr/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\n    935 kwds_defaults = _refine_defaults_read(\n    936     dialect,\n    937     delimiter,\n   (...)\n    946     defaults={\"delimiter\": \",\"},\n    947 )\n    948 kwds.update(kwds_defaults)\n--> 950 return _read(filepath_or_buffer, kwds)\n\nFile /usr/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605, in _read(filepath_or_buffer, kwds)\n    602 _validate_names(kwds.get(\"names\", None))\n    604 # Create the parser.\n--> 605 parser = TextFileReader(filepath_or_buffer, **kwds)\n    607 if chunksize or iterator:\n    608     return parser\n\nFile /usr/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442, in TextFileReader.__init__(self, f, engine, **kwds)\n   1439     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1441 self.handles: IOHandles | None = None\n-> 1442 self._engine = self._make_engine(f, self.engine)\n\nFile /usr/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735, in TextFileReader._make_engine(self, f, engine)\n   1733     if \"b\" not in mode:\n   1734         mode += \"b\"\n-> 1735 self.handles = get_handle(\n   1736     f,\n   1737     mode,\n   1738     encoding=self.options.get(\"encoding\", None),\n   1739     compression=self.options.get(\"compression\", None),\n   1740     memory_map=self.options.get(\"memory_map\", False),\n   1741     is_text=is_text,\n   1742     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1743     storage_options=self.options.get(\"storage_options\", None),\n   1744 )\n   1745 assert self.handles is not None\n   1746 f = self.handles.handle\n\nFile /usr/lib/python3.11/site-packages/pandas/io/common.py:856, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    851 elif isinstance(handle, str):\n    852     # Check whether the filename is to be opened in binary mode.\n    853     # Binary mode does not support 'encoding' and 'newline'.\n    854     if ioargs.encoding and \"b\" not in ioargs.mode:\n    855         # Encoding\n--> 856         handle = open(\n    857             handle,\n    858             ioargs.mode,\n    859             encoding=ioargs.encoding,\n    860             errors=errors,\n    861             newline=\"\",\n    862         )\n    863     else:\n    864         # Binary mode\n    865         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: '../../DATA/proposals/snapshot_proposals.csv'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPapermillExecutionError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./votes/snapshot/get_snapshot_votes.ipynb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[53], line 8\u001b[0m, in \u001b[0;36mrun_notebook\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_notebook\u001b[39m(path):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mpm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_notebook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/papermill/execute.py:128\u001b[0m, in \u001b[0;36mexecute_notebook\u001b[0;34m(input_path, output_path, parameters, engine_name, request_save_on_cell_execute, prepare_only, kernel_name, language, progress_bar, log_output, stdout_file, stderr_file, start_timeout, report_mode, cwd, **engine_kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         nb \u001b[38;5;241m=\u001b[39m papermill_engines\u001b[38;5;241m.\u001b[39mexecute_notebook_with_engine(\n\u001b[1;32m    114\u001b[0m             engine_name,\n\u001b[1;32m    115\u001b[0m             nb,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mengine_kwargs\n\u001b[1;32m    125\u001b[0m         )\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# Check for errors first (it saves on error before raising)\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     \u001b[43mraise_for_execution_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# Write final output in case the engine didn't write it on cell completion.\u001b[39;00m\n\u001b[1;32m    131\u001b[0m write_ipynb(nb, output_path)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/papermill/execute.py:232\u001b[0m, in \u001b[0;36mraise_for_execution_errors\u001b[0;34m(nb, output_path)\u001b[0m\n\u001b[1;32m    229\u001b[0m nb\u001b[38;5;241m.\u001b[39mcells\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, error_msg_cell)\n\u001b[1;32m    231\u001b[0m write_ipynb(nb, output_path)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mPapermillExecutionError\u001b[0m: \n---------------------------------------------------------------------------\nException encountered at \"In [2]\":\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[2], line 3\n      1 # read in ../../DATA/deployments/snapshot_deployments.csv\n      2 import pandas as pd\n----> 3 df = pd.read_csv('../../DATA/proposals/snapshot_proposals.csv')\n      4 df.head()\n\nFile /usr/lib/python3.11/site-packages/pandas/util/_decorators.py:211, in deprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper(*args, **kwargs)\n    209     else:\n    210         kwargs[new_arg_name] = new_arg_value\n--> 211 return func(*args, **kwargs)\n\nFile /usr/lib/python3.11/site-packages/pandas/util/_decorators.py:331, in deprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper(*args, **kwargs)\n    325 if len(args) > num_allow_args:\n    326     warnings.warn(\n    327         msg.format(arguments=_format_argument_list(allow_args)),\n    328         FutureWarning,\n    329         stacklevel=find_stack_level(),\n    330     )\n--> 331 return func(*args, **kwargs)\n\nFile /usr/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950, in read_csv(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\n    935 kwds_defaults = _refine_defaults_read(\n    936     dialect,\n    937     delimiter,\n   (...)\n    946     defaults={\"delimiter\": \",\"},\n    947 )\n    948 kwds.update(kwds_defaults)\n--> 950 return _read(filepath_or_buffer, kwds)\n\nFile /usr/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605, in _read(filepath_or_buffer, kwds)\n    602 _validate_names(kwds.get(\"names\", None))\n    604 # Create the parser.\n--> 605 parser = TextFileReader(filepath_or_buffer, **kwds)\n    607 if chunksize or iterator:\n    608     return parser\n\nFile /usr/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442, in TextFileReader.__init__(self, f, engine, **kwds)\n   1439     self.options[\"has_index_names\"] = kwds[\"has_index_names\"]\n   1441 self.handles: IOHandles | None = None\n-> 1442 self._engine = self._make_engine(f, self.engine)\n\nFile /usr/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735, in TextFileReader._make_engine(self, f, engine)\n   1733     if \"b\" not in mode:\n   1734         mode += \"b\"\n-> 1735 self.handles = get_handle(\n   1736     f,\n   1737     mode,\n   1738     encoding=self.options.get(\"encoding\", None),\n   1739     compression=self.options.get(\"compression\", None),\n   1740     memory_map=self.options.get(\"memory_map\", False),\n   1741     is_text=is_text,\n   1742     errors=self.options.get(\"encoding_errors\", \"strict\"),\n   1743     storage_options=self.options.get(\"storage_options\", None),\n   1744 )\n   1745 assert self.handles is not None\n   1746 f = self.handles.handle\n\nFile /usr/lib/python3.11/site-packages/pandas/io/common.py:856, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\n    851 elif isinstance(handle, str):\n    852     # Check whether the filename is to be opened in binary mode.\n    853     # Binary mode does not support 'encoding' and 'newline'.\n    854     if ioargs.encoding and \"b\" not in ioargs.mode:\n    855         # Encoding\n--> 856         handle = open(\n    857             handle,\n    858             ioargs.mode,\n    859             encoding=ioargs.encoding,\n    860             errors=errors,\n    861             newline=\"\",\n    862         )\n    863     else:\n    864         # Binary mode\n    865         handle = open(handle, ioargs.mode)\n\nFileNotFoundError: [Errno 2] No such file or directory: '../../DATA/proposals/snapshot_proposals.csv'\n"
     ]
    }
   ],
   "source": [
    "run_notebook('./votes/snapshot/get_snapshot_votes.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
